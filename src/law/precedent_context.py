import os
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.documents import Document
# precedent_searchì—ì„œ íŒë¡€ ê²€ìƒ‰ ë° íŒŒì‹± ê´€ë ¨ í•¨ìˆ˜ë§Œ importí•©ë‹ˆë‹¤.
from .precedent_search import search_precedent_list, get_precedent_detail_text, parse_precedent_content 
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œì»¬ DB ì €ì¥ ê²½ë¡œ ë° ëŒ€ìƒ ê²€ìƒ‰ì–´ ì •ì˜
PREC_DB_PATH = "../data/faiss_precedent_db" 
# DB êµ¬ì¶• ì‹œ ê²€ìƒ‰í•  í•µì‹¬ í‚¤ì›Œë“œ ëª©ë¡
TARGET_QUERIES = ["ë¶€ë‹¹ í•´ê³ ", "ìœ„ì•½ ì˜ˆì •", "ì§•ë²Œì  ì†í•´ë°°ìƒ", "ë¶ˆê³µì • ì•½ì •", "ê·¼ë¡œê¸°ì¤€ë²•"]

class PrecedentContextManager:
    """
    íŒë¡€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘, ì„ë² ë”©í•˜ê³  FAISS ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê´€ë¦¬í•˜ì—¬
    RAG(Retrieval-Augmented Generation)ì— ì‚¬ìš©í•  ë¬¸ë§¥ì„ ì œê³µí•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    def __init__(self):
        self.vectorstore = None  # FAISS ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì €ì¥í•  ë³€ìˆ˜
        self.target_queries = TARGET_QUERIES
        # í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        self.embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli")

    def initialize_database(self, max_pages=1, display=10):
        """
        ë¡œì»¬ DBë¥¼ í™•ì¸í•˜ì—¬ DBë¥¼ ë¡œë“œí•˜ê±°ë‚˜, ì—†ìœ¼ë©´ ë²•ì œì²˜ APIë¥¼ í†µí•´ ìƒˆë¡œ êµ¬ì¶• í›„ ì €ì¥í•©ë‹ˆë‹¤.

        :param max_pages: ê° ì¿¼ë¦¬ë‹¹ ìµœëŒ€ ëª‡ í˜ì´ì§€ê¹Œì§€ ê²€ìƒ‰í• ì§€ ì§€ì •í•©ë‹ˆë‹¤. (ê¸°ë³¸ê°’: 1 í˜ì´ì§€)
        :param display: í˜ì´ì§€ë‹¹ ê²€ìƒ‰í•  íŒë¡€ì˜ ìµœëŒ€ ê°œìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. (ê¸°ë³¸ê°’: 10ê±´)
        """
        if self.vectorstore is not None:
            print("ğŸ’¡ íŒë¡€ DBê°€ ì´ë¯¸ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return

        # 1. ë¡œì»¬ DB íŒŒì¼ ì¡´ì¬ í™•ì¸ ë° ë¡œë“œ
        if os.path.exists(PREC_DB_PATH) and os.path.isdir(PREC_DB_PATH):
            print(f"âœ… [ì´ˆê¸°í™”] ê¸°ì¡´ íŒë¡€ DB ë¡œë“œ ì¤‘... (ê²½ë¡œ: {PREC_DB_PATH})")
            try:
                # DB ë¡œë“œ
                self.vectorstore = FAISS.load_local(PREC_DB_PATH, self.embeddings, allow_dangerous_deserialization=True)
                print("âœ… [ì´ˆê¸°í™”] íŒë¡€ DB ë¡œë“œ ì™„ë£Œ!")
                return
            except Exception as e:
                print(f"âš ï¸ ê¸°ì¡´ DB ë¡œë“œ ì‹¤íŒ¨: {e}. DBë¥¼ ìƒˆë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤.")
        
        # 2. ì‹ ê·œ DB êµ¬ì¶•
        print(f"ğŸ“š [ì´ˆê¸°í™”] í•„ìˆ˜ íŒë¡€ ë°ì´í„° ì‹ ê·œ êµ¬ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤. (í˜ì´ì§€ë‹¹ {display}ê±´, ìµœëŒ€ {max_pages} í˜ì´ì§€)")
        all_docs = []       # ìˆ˜ì§‘ëœ ëª¨ë“  Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
        precedent_ids = set() # íŒë¡€ì¼ë ¨ë²ˆí˜¸ ì¤‘ë³µ ë°©ì§€ìš© Set

        for query in self.target_queries:
            print(f"\n  ğŸ” '{query}' ê²€ìƒ‰ ì¤‘...")
            page = 1
            
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¤‘ë³µ ì—†ì´ ìˆ˜ì§‘
            while page <= max_pages: 
                # íŒë¡€ ëª©ë¡ ê²€ìƒ‰
                precedents, total_count = search_precedent_list(query, display=display, page=page)
                
                if not precedents:
                    break
                
                total_pages = (total_count + display - 1) // display
                print(f"  ğŸ“¥ í˜ì´ì§€ {page}/{total_pages} ({len(precedents)}ê±´) íŒë¡€ ìƒì„¸ ë‹¤ìš´ë¡œë“œ ë° íŒŒì‹±...")

                for prec_info in precedents:
                    # ==========================================
                    # [ìˆ˜ì •ë¨] ë°ì´í„° íƒ€ì… ë°©ì–´ ì½”ë“œ ì¶”ê°€ êµ¬ê°„
                    # ==========================================
                    
                    # 1. ë¬¸ìì—´(String)ì´ ì˜ëª» ë“¤ì–´ì˜¨ ê²½ìš° ì²´í¬
                    if isinstance(prec_info, str):
                        print(f"âš ï¸ [ê²½ê³ ] ì˜ˆìƒì¹˜ ëª»í•œ ë°ì´í„° íƒ€ì…(str) ë°œê²¬ -> ê±´ë„ˆëœ€. ë‚´ìš©: {prec_info}")
                        continue
                    
                    # 2. ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš° ì²´í¬
                    if not isinstance(prec_info, dict):
                        print(f"âš ï¸ [ê²½ê³ ] ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ë°ì´í„° íƒ€ì…({type(prec_info)}) ë°œê²¬ -> ê±´ë„ˆëœ€.")
                        continue

                    # 3. ì•ˆì „í•˜ê²Œ .get() í˜¸ì¶œ
                    prec_id = prec_info.get("íŒë¡€ì¼ë ¨ë²ˆí˜¸")
                    
                    if not prec_id or prec_id in precedent_ids:
                        continue 
                    
                    # 2-1. íŒë¡€ ìƒì„¸ ë‚´ìš©(ìš”ì§€, íŒì‹œì‚¬í•­) ê°€ì ¸ì˜¤ê¸°
                    summary_list, holding = get_precedent_detail_text(prec_id)
                    
                    # 2-2. ë¬¸ì„œ ê°ì²´ë¡œ ë³€í™˜ ë° ì¤‘ë³µ ê²€ì‚¬ í›„ ì¶”ê°€
                    full_text, metadata = parse_precedent_content(summary_list, holding, prec_info)
                    
                    if full_text:
                        doc = Document(page_content=full_text, metadata=metadata)
                        all_docs.append(doc)
                        precedent_ids.add(prec_id) 

                page += 1
                
        if not all_docs:
            print("âŒ ì €ì¥í•  íŒë¡€ ë°ì´í„°ê°€ ì—†ì–´ DB ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        # 3. ë²¡í„° DB ìƒì„± ë° ë¡œì»¬ ì €ì¥
        print(f"\nâš¡ ì´ {len(all_docs)}ê°œ íŒë¡€ ë²¡í„°í™” ë° DB ì €ì¥ ì‹œì‘...")
        self.vectorstore = FAISS.from_documents(all_docs, self.embeddings)
        
        os.makedirs(os.path.dirname(PREC_DB_PATH), exist_ok=True)
        self.vectorstore.save_local(PREC_DB_PATH)
        
        print(f"âœ… íŒë¡€ DB ì‹ ê·œ êµ¬ì¶• ë° ì €ì¥ ì™„ë£Œ! (ì´ {len(all_docs)}ê°œ íŒë¡€, ê²½ë¡œ: {os.path.abspath(PREC_DB_PATH)})")


    def search_relevant_precedents(self, query, k=2):
        """
        ë¡œì»¬ì— ë¡œë“œëœ DBì—ì„œ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ íŒë¡€ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        :param query: ê²€ìƒ‰ì„ ìœ„í•œ ì‚¬ìš©ì ì§ˆë¬¸(í…ìŠ¤íŠ¸)
        :param k: ë°˜í™˜í•  ê²€ìƒ‰ ê²°ê³¼(Document)ì˜ ìµœëŒ€ ê°œìˆ˜ì…ë‹ˆë‹¤. (ê¸°ë³¸ê°’: 2)
        :return: ê²€ìƒ‰ëœ íŒë¡€ ë‚´ìš©(page_content) ë¦¬ìŠ¤íŠ¸
        """
        # DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¡œë“œ ì‹œë„
        if not self.vectorstore:
            self.initialize_database()
        
        if not self.vectorstore:
            print("âš ï¸ íŒë¡€ DBê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        print(f"ğŸ” íŒë¡€ DBì—ì„œ '{query[:20]}...' ê´€ë ¨ íŒë¡€ {k}ê°œ ê²€ìƒ‰ ì¤‘...")
        # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
        docs = self.vectorstore.similarity_search(query, k=k)
        return [doc.page_content for doc in docs]